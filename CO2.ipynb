{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from https://brunelvis.org/jar/spark-kernel-brunel-all-1.2.jar\n",
      "Finished download of spark-kernel-brunel-all-1.2.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar -magic https://brunelvis.org/jar/spark-kernel-brunel-all-1.2.jar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking com.databricks:spark-csv_2.10:1.3.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/var/folders/qy/z43k21xd5v9db55bkb41svmw0000gn/T/toree_add_deps7295586412712904848/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /var/folders/qy/z43k21xd5v9db55bkb41svmw0000gn/T/toree_add_deps7295586412712904848/https/repo1.maven.org/maven2/org/apache/commons/commons-csv/1.1/commons-csv-1.1.jar\n",
      "-> New file at /var/folders/qy/z43k21xd5v9db55bkb41svmw0000gn/T/toree_add_deps7295586412712904848/https/repo1.maven.org/maven2/com/databricks/spark-csv_2.10/1.3.0/spark-csv_2.10-1.3.0.jar\n",
      "-> New file at /var/folders/qy/z43k21xd5v9db55bkb41svmw0000gn/T/toree_add_deps7295586412712904848/https/repo1.maven.org/maven2/com/univocity/univocity-parsers/1.5.1/univocity-parsers-1.5.1.jar\n"
     ]
    }
   ],
   "source": [
    "%AddDeps com.databricks spark-csv_2.10 1.3.0 --transitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.sql.SQLContext\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.functions._ \n",
    "\n",
    "val sqlContext = new SQLContext(sc)\n",
    "\n",
    "//Data is not aggregated\n",
    "val co2 = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"Co2all.csv\")\n",
    "\n",
    "//Add a column that has Year as a true date type\n",
    "val convertDate = udf {\n",
    "    (year:Int) => year+ \"-01-01 \" +year + \" 00:00 UTC\"\n",
    "}\n",
    "val co2dates = co2.withColumn(\"year_as_date\", to_date(convertDate(co2(\"Year\"))) )\n",
    "\n",
    "//Data is aggregated by Spark\n",
    "val co2agg = co2.groupBy(\"CO2 per capita\").agg( avg(\"value\") as \"Mean Co2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
